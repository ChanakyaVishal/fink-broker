#!/usr/bin/env python
# Copyright 2019 AstroLab Software
# Author: Abhishek Chauhan
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Distribute the alerts to users

1. Use the Alert data that is stored in the Science database (HBase)
2. Serialize into Avro
3. Publish to Kafka Topics
"""

import argparse
import json

from fink_broker.parser import getargs
from fink_broker.sparkUtils import init_sparksession, to_avro
from pyspark.sql.functions import struct, col

def main():
    parser = argparse.ArgumentParser(description = __doc__)
    args = getargs(parser)

    # Get or create a Spark Session
    spark = init_sparksession(
        name = "distribution", shuffle_partitions = 2, log_level = "ERROR")

    # Read the catalog file generated by raw2science
    with open('catalog.json') as f:
        catalog = json.load(f)

    # Read the HBase and create a DataFrame
    df = spark.read.option("catalog", catalog)\
        .format("org.apache.spark.sql.execution.datasources.hbase")\
        .load()

    # For a kafka output the dataframe should have the following columns:
    # key: (optional) Using a key can ensure reading duplicate data
    #                 as Kafka supports 'at least once' write semantics
    #                 and might result in duplicate writing
    # value: (required)
    # topic: (*optional)
    # *if a topic field is not present in the dataframe it has to be given
    # while writng to kafka

    #--------------------------------------------------------------------------#
    # # For testing publish only a selected columns
    # col_list = ["objectId", "candid", "simbadType",
    #             "candidate_jd", "candidate_pid",
    #             "candidate_ra", "candidate_dec"]
    #
    # # The avro schema for the filtered DataFrame will be as shown below:
    # avro_schema_distribution = """
    # {
    #     "doc" : "avro schema for alert distribution",
    #     "name" : "ztf_filtered",
    #     "type" : "record",
    #     "fields" : [
    #         {"name" : "objectId", "type" : "string"},
    #         {"name" : "candid", "type" : "long"},
    #         {"name" : "simbadType", "type" : "string"},
    #         {"name" : "candidate_jd", "type" : "double"},
    #         {"name" : "candidate_pid", "type" : "long"},
    #         {"name" : "candidate_ra", "type" : "double"},
    #         {"name" : "candidate_dec", "type" : "double"}
    #     ]
    #
    # }"""
    #--------------------------------------------------------------------------#
    #--------------------------------------------------------------------------#
    # For testing publish only a selected columns
    col_list = ["objectId", 'simbadType']

    # The avro schema for the filtered DataFrame will be as shown below:
    avro_schema_distribution = """
    {
        "doc" : "avro schema for alert distribution",
        "name" : "ztf_filtered",
        "type" : "record",
        "fields" : [
            {"name" : "objectId", "type" : "string"},
            {"name" : "simbadType", "type" : "string"}
        ]

    }"""
    #--------------------------------------------------------------------------#

    # Create a struct of the listed columns
    df_struct = df.select(struct(col_list).alias("struct"))

    # Convert into avro data for publishing to Kafka
    df_kafka = df_struct.select(to_avro(col("struct")).alias("value"))

    # Publish to a test topic (Ensure that the topic exists on the Kafka Server)
    topic = "test_distribution"

    df_kafka\
        .write\
        .format("kafka")\
        .option("kafka.bootstrap.servers", "localhost:9093")\
        .option("topic", topic)\
        .save()

if __name__ == "__main__":
    main()
